{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a57bac",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/osgeokr/torchgeo-explained/blob/main/TorchGeo%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EA%B0%9D%EC%B2%B4%20%ED%83%90%EC%A7%80(Object%20Detection).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gjR-XMGZT8Ro",
   "metadata": {
    "id": "gjR-XMGZT8Ro"
   },
   "source": [
    "# NWPU VHR-10 데이터셋\n",
    "\n",
    "[VHR-10](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#vhr-10)은 중국 서북공업대학교(NWPU: Northwestern Polytechnical University)에서 제공하는 초고해상도(Very High Resolution) 10개 클래스 원격탐사 이미지 데이터셋입니다.\n",
    "\n",
    "총 800장의 초고해상도(VHR) 광학 원격탐사 이미지로 구성되어 있으며, 이 중 715장의 컬러 이미지는 Google Earth로부터 0.5에서 2m 사이의 공간 해상도로 획득되었고, 나머지 85장의 팬 샤프닝된 컬러 적외선(CIR: Color InfraRed) 이미지는 Vaihingen(바이힝겐) 데이터로부터 0.08m 공간해상도로 획득되었습니다.\n",
    "\n",
    "데이터셋은 두 세트로 나뉩니다:\n",
    "\n",
    "양성 이미지 세트(650장)는 이미지 내에 적어도 하나의 대상이 포함되어 있는 이미지입니다.\n",
    "\n",
    "- Positive image set(양성 이미지 세트: 650장): 이미지 내에 적어도 하나의 대상이 포함되어 있는 이미지\n",
    "- Negative image set(음성 이미지 세트: 150장): 어떤 대상도 포함하지 않은 이미지\n",
    "\n",
    "양성 이미지 세트는 다음과 같은 열 클래스의 객체를 포함합니다:\n",
    "\n",
    "- Airplanes(비행기) (757)\n",
    "- Ships(배) (302)\n",
    "- Storage tanks(저장 탱크) (655)\n",
    "- Baseball diamonds(야구장) (390)\n",
    "- Tennis courts(테니스 코트) (524)\n",
    "- Basketball courts(농구장) (159)\n",
    "- Ground track fields(육상 트랙 필드) (163)\n",
    "- Harbors(항구) (224)\n",
    "- Bridges(다리) (124)\n",
    "- Vehicles(차량) (477)\n",
    "\n",
    "객체 탐지 바운딩 박스(object detection bounding boxes)와 인스턴스 분할 마스크(instance segmentation masks)를 포함합니다. 이 데이터셋을 연구에 사용하는 경우, 다음 논문들을 인용해야 합니다:\n",
    "- https://doi.org/10.1016/j.isprsjprs.2014.10.002\n",
    "- https://doi.org/10.1109/IGARSS.2019.8898573\n",
    "- https://doi.org/10.3390/rs12060989\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HgepFtB2iM1U",
   "metadata": {
    "id": "HgepFtB2iM1U"
   },
   "source": [
    "이 데이터셋을 사용하기 위해서는 다음 추가 라이브러리들이 설치되어야 합니다:\n",
    "\n",
    "- \"양성\" 이미지 세트에 대한 annotations.json 파일을 불러오기 위한 pycocotools\n",
    "- 데이터셋이 RAR 파일로 저장되어 있으므로, 이를 추출하기 위한 rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mpu0ICh7h5UQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpu0ICh7h5UQ",
    "outputId": "6848e1bd-9102-48a4-ac4c-39ed061180c6"
   },
   "outputs": [],
   "source": [
    "%pip install -q -U torchgeo\n",
    "%pip install -q -U pycocotools\n",
    "%pip install -q -U rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff0785",
   "metadata": {
    "id": "d7ff0785"
   },
   "outputs": [],
   "source": [
    "import torchgeo\n",
    "import torch\n",
    "from torchgeo.trainers import ObjectDetectionTask\n",
    "from torchgeo.datasets import VHR10\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6ec01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "64d6ec01",
    "outputId": "da9df21a-c7be-4082-c5a9-694bd6d715c2"
   },
   "outputs": [],
   "source": [
    "torchgeo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FrF22sEak7cH",
   "metadata": {
    "id": "FrF22sEak7cH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = 'data/VHR10/'\n",
    "os.makedirs(dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1czUSYi5ht",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "cc1czUSYi5ht",
    "outputId": "b1957f5e-13d0-434f-dbaa-8aa432fe7955"
   },
   "outputs": [],
   "source": [
    "ds = VHR10(root='data/VHR10/', split='positive', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a565672",
   "metadata": {
    "id": "8a565672",
    "outputId": "442c372b-0181-4b4a-e4d0-fac114102fb8"
   },
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    sample[\"image\"] = sample[\"image\"].float() / 255.0\n",
    "    return sample\n",
    "\n",
    "ds = VHR10(root='data/VHR10/', split='positive', transforms=preprocess, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4aab35",
   "metadata": {
    "id": "4f4aab35",
    "outputId": "e70e3fbd-86cb-45ee-aa3f-757e0934b5d8"
   },
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde065f",
   "metadata": {
    "id": "abde065f",
    "outputId": "66bbd99d-f370-44c2-f0e2-9e6fadda06d8"
   },
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe2f86",
   "metadata": {
    "id": "47fe2f86",
    "outputId": "8aa8b1f0-fa1d-4c29-eef7-521393220d0a"
   },
   "outputs": [],
   "source": [
    "ds[0][\"image\"].shape, ds[1][\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38476acc",
   "metadata": {
    "id": "38476acc",
    "outputId": "2dcb08d1-9e62-4727-cfd5-e0f042762147"
   },
   "outputs": [],
   "source": [
    "ds.plot(ds[1])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d9fd0",
   "metadata": {
    "id": "457d9fd0"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"image\": [item[\"image\"] for item in batch],\n",
    "        \"boxes\": [item[\"boxes\"] for item in batch],\n",
    "        \"labels\": [item[\"labels\"] for item in batch],\n",
    "        \"masks\": [item[\"masks\"] for item in batch],\n",
    "    }\n",
    "    return new_batch\n",
    "\n",
    "dl = DataLoader(ds, batch_size=32, num_workers=8, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecc798",
   "metadata": {
    "id": "57ecc798"
   },
   "outputs": [],
   "source": [
    "# The current (torchgeo 0.5.0) ObjectDetectionTask does not seem to support variable\n",
    "# size inputs. We can quickly fix this by subclassing it and overriding the\n",
    "# training_step method.\n",
    "class VariableSizeInputObjectDetectionTask(ObjectDetectionTask):\n",
    "    def training_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x = batch[\"image\"]\n",
    "        batch_size = len(x)  # we change this line to support variable size inputs\n",
    "        y = [\n",
    "            {\"boxes\": batch[\"boxes\"][i], \"labels\": batch[\"labels\"][i]}\n",
    "            for i in range(batch_size)\n",
    "        ]\n",
    "        loss_dict = self(x, y)\n",
    "        train_loss: Tensor = sum(loss_dict.values())\n",
    "        self.log_dict(loss_dict)\n",
    "        return train_loss\n",
    "\n",
    "\n",
    "task = VariableSizeInputObjectDetectionTask(\n",
    "    model=\"faster-rcnn\",\n",
    "    backbone=\"resnet18\",\n",
    "    weights=True,\n",
    "    in_channels=3,\n",
    "    num_classes=11,\n",
    "    trainable_layers=3,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    freeze_backbone=False,\n",
    ")\n",
    "task.monitor = \"loss_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac66e",
   "metadata": {
    "id": "ac7ac66e",
    "outputId": "9d7c4cd2-21a8-47a8-a952-20e8808062c5"
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"logs/\",\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    min_epochs=6,\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec13c4e",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e6113179c83a42799016f60311a87fed"
     ]
    },
    "id": "5ec13c4e",
    "outputId": "6505f30b-e780-49d8-9cb2-a736c0130124"
   },
   "outputs": [],
   "source": [
    "trainer.fit(task, train_dataloaders=dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c132e",
   "metadata": {
    "id": "315c132e"
   },
   "source": [
    "## Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758f62a",
   "metadata": {
    "id": "c758f62a"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dl))\n",
    "#batch[\"image\"] = [image.to(\"cuda:0\") for image in batch[\"image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb11e0c",
   "metadata": {
    "id": "4cb11e0c"
   },
   "outputs": [],
   "source": [
    "model = task.model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(batch[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b91d6",
   "metadata": {
    "id": "dd1b91d6"
   },
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "sample = {\n",
    "    \"image\": batch[\"image\"][batch_idx],\n",
    "    \"boxes\": batch[\"boxes\"][batch_idx],\n",
    "    \"labels\": batch[\"labels\"][batch_idx],\n",
    "    \"masks\": batch[\"masks\"][batch_idx],\n",
    "    \"prediction_labels\": out[batch_idx][\"labels\"],\n",
    "    \"prediction_boxes\": out[batch_idx][\"boxes\"],\n",
    "    \"prediction_scores\": out[batch_idx][\"scores\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfbe8e",
   "metadata": {
    "id": "88dfbe8e",
    "outputId": "3fd1ccea-9378-45d3-da49-1d1971c62bbd"
   },
   "outputs": [],
   "source": [
    "ds.plot(sample)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30b721",
   "metadata": {
    "id": "be30b721"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
